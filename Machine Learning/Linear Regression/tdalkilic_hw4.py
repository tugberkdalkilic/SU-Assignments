# -*- coding: utf-8 -*-
"""tdalkilic_hw4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mRIRALxpOy4Yvp3obsG1IkYqlmYs_uA3

# Load the dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt                   

df = pd.read_csv('https://raw.githubusercontent.com/OpenClassrooms-Student-Center/Evaluate-Improve-Models/master/house_prices.csv')
df.sample(5)

"""# "Garage Area" and "SalesPrice" features are selected to analyze."""

new_df = df[['Garage Area','SalesPrice']]

"""## Convert the data into numpy arrays of two variables, X and y."""

X = np.array(df[['Garage Area']])
y = np.array(df[['SalesPrice']])
print(X.shape) # Vewing the shape of X
print(y.shape) # Vewing the shape of y

"""## Split train and test data with 0.2 ratio."""

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.2,random_state=15)

"""# Linear Regression
Train a linear regression.
"""

from sklearn import linear_model 

regressor = linear_model.LinearRegression()

regressor.fit(X_train,y_train)

"""## Calculate train and test R2."""

from sklearn.metrics import r2_score

y_pred = regressor.predict(X_train)
print("Train:", r2_score(y_train,y_pred))

y_pred2 = regressor.predict(X_test)
print("Test:", r2_score(y_test,y_pred2))

"""## Print the bias and the slope."""

print('Regressor coeffient or slope:',regressor.coef_[0][0])
print('Interception point with axis:',regressor.intercept_[0])

"""## Plot the test set with scatter plot and add the linear regression model line.
Remember linear regression recitation.
"""

# Plot a graph with X_test vs y_test
plt.scatter(X_test,y_test,color="green")
# Regressior line showing
plt.plot(X_train,regressor.predict(X_train),color="red",linewidth=3)
plt.title('Regression(Test Set)')
plt.xlabel('Garage Area')
plt.ylabel('SalesPrice')
plt.show()

"""# Multiple Linear Regression
Select all features.
"""

X = np.array(df.loc[:, df.columns != 'SalesPrice'])
y = np.array(df[['SalesPrice']])
print(X.shape) # Vewing the shape of X
print(y.shape) # Vewing the shape of y

"""## Rescale the input features. Use MinMaxScaler."""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

"""## Train test split."""

X_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=15)

"""## Fit regression model."""

regress= linear_model.LinearRegression()
regress.fit(X_train,y_train)

"""## Calculate train and test R2."""

pred_train = regress.predict(X_train)
print ("Train:" , r2_score(y_train,pred_train))

pred_test = regress.predict(x_test)
print ("Test:" , r2_score(y_test,pred_test))

"""## Print the regression coefficients."""

print('Regressor coeffients for multiple linear regression:', regress.coef_)

"""# Ridge Regression
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html

https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html

## Use cross-validation to estimate alpha. Set the fold size to 5.
"""

from sklearn.model_selection import KFold
from sklearn.linear_model import RidgeCV
kfold = KFold(n_splits=5)

alphas_=[1e-3, 1e-2, 1e-1, 1, 2, 5, 8, 10]

model_rcv = RidgeCV(cv=kfold, alphas=alphas_)
model_rcv.fit(X_train, y_train)

"""## Calculate the train and test R2."""

predictions = model_rcv.predict(X_train)
print("Train:", r2_score(y_train, predictions))

predictions = model_rcv.predict(x_test)
print("Test:", r2_score(y_test, predictions))

"""## Print the best alpha."""

print("Alpha:", model_rcv.alpha_)

"""## Print the regression coefficients."""

print('Regressor coeffients for ridge regression:',model_rcv.coef_)